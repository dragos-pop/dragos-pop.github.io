<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>MIDIGPT</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="index.html" class="image avatar"><img src="images/avatar1.jpg" alt="" /></a>
					<h1><strong>Dragos Pop</strong><br />
 						Data Science & Engineering</h1>
				</div>
			</header>


		<!-- Main -->
			<div id="main">
				<!-- One -->
					<section id="one">
						<header class="major">
							<h1>Generating music from Raw MIDI<br />
							</h1>
						</header>
						<h3>Aug 2023 ~ Vrije University Amsterdam<br /><br /></h3>
						<p align="justify"><b>Length: </b> &nbsp; 11 mo<br /><br />

							<b>Programming language: </b> Python (NumPy, Random, Math, PyYAML, PyTorch, PyTorch Lightning, W&B,
							TensorBoard, Python Fire)<br /><br />

							<b>Data: </b> &nbsp;Raw MIDI representations composed of the following features: type (7 event
							types), note (128 notes), velocity (128 velocity levels), channel (16 MIDI channels),
							instrument (128 MIDI instruments), and tick (note on and off).<br /><br />

							<b>Problem description: </b><br />
							Develop and train GPT-like transformers on HPC to generate music from Raw MIDI<br /><br />

							<b>Approach & Results: </b><br />
							Starting from the decoder-only skeleton architecture displayed below, several structural
							adjustments were implemented, one by one, and evaluated after training the respective transformers
							on HPC and comparing their losses in W&B. The list of conducted experiments includes weight scaling,
							<a href="https://www.cs.toronto.edu/~mvolkovs/ICML2020_tfixup.pdf" target="_blank">T-Fixup initialization</a>,
							<a href="https://arxiv.org/pdf/1803.05407v3.pdf" target="_blank">Stochastic Weight Averaging (SWA)</a>,
							<a href="https://arxiv.org/pdf/1910.05895.pdf" target="_blank">Scalenorm and Fixnorm</a>.
							Additionally, the model was developed to enable multi-node training and resume learning from checkpoints.
							Lastly, its embedding dimension, batch throughput, learning rate, and dropout rate were optimized, and the
							installation and utilization instructions were drafted.

							<br /><br />
							<img src="images/Fig42.jpg" alt="Default Architecture" width="180" height="420">
							<br /><br />

							The performance of the transformers was quantified using the amount of information a model
							can compress per bit, measured in bits per event (the lower, the better). Regarding the
							enhancements incorporated, one that produced remarkable results is mixed precision.
							In the image below, one can see the validation losses of two models, out of which one uses mixed precision.
							Even though both transformers were trained for 120 hours, the one with mixed precision was three times faster
							without affecting the loss.

							<br /><br />
							<img src="images/Fig43.jpg" alt="Validation Loss Mixed Precision" width="590" height="280">
							<br /><br />

							The next successful experiment involved adjusting the embedding initialization to PyTorch's
							default function, nn.Embedding(). Consequently, the validation curve was improved by 2%, as
							displayed in the next chart.

							<br /><br />
							<img src="images/Fig44.jpg" alt="Validation Loss Data Augmentation" width="590" height="280">
							<br /><br />

							In order to reduce overfitting, various data augmentation techniques were applied, resulting
							in another significant decrease in the validation curve, as the figure below suggests.

							<br /><br />
							<img src="images/Fig45.jpg" alt="Validation Loss Embedding Initialization" width="590" height="280">
							<br /><br />

							Finally, the best model was used to generate the following samples. These are composed
							starting with a seed extracted from an existing song, followed by a whistle, which marks the beginning of
							the music generated by the model. Accordingly, one can notice that the transformer can reliably
							produce chords and learn the timing from the seed.<br /><br />

							<audio controls>
								<source src="songs/sample1.mp3" type="audio/mpeg">
								Your browser does not support the audio element.
							</audio>

							<audio controls>
								<source src="songs/sample2.mp3" type="audio/mpeg">
								Your browser does not support the audio element.
							</audio>

							<br />

						</p>
						<ul class="actions">
							<li><a href="Sales Forecasting F.html" class="button">Previous project</a>
<!--							<a href="Sales Forecasting F.html" class="button">Next project</a></li>-->
						</ul>
						<ul class="actions">
							<li><a href="index.html" class="button">Home</a></li>
						</ul>
					</section>

				<!-- Three -->
					<section id="three">
							<div class="col-4 col-12-small">
								<ul class="labeled-icons">
									<li>
										<h3 class="icon solid fa-home"><span class="label">Address</span></h3>
										Singapore<br />
									</li>
								</ul>
							</div>
					</section>
			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/dragos-pop/" target="_blank" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/dragos-pop" target="_blank" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="https://www.kaggle.com/dragospop" target="_blank" class="icon brands alt fa-kaggle"><span class="label">Kaggle</span></a></li>
						<li><a href="https://medium.com/@dragos-pop"  target="_blank" class="icon brands alt fa-medium"><span class="label">Medium</span></a></li>
						<li><a href="https://wandb.ai/d-a-pop" target="_blank"><span class="label">W&B</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Dragos Pop</li>
					</ul>
				</div>
			</footer>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
